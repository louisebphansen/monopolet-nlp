{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5f5860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np\n",
    "import regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdf6664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "data_path = os.path.join('..', 'data', \"Louise-Prep-Data-SaraOgMonopolet.json\")\n",
    "df = pd.read_json(data_path)\n",
    "\n",
    "# remove row 2, iloc 1 (solutions do not match the dilemma)\n",
    "df = df.drop(df.index[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae6a9fd",
   "metadata": {},
   "source": [
    "We need to do some data cleaning. Some solutions contain jokes, which is specified in the text. Others contain strange metadata, such as 'Deltagere: {guest_sender}' etc. We use regex to clean these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eae723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_jokes(df):\n",
    "    \n",
    "    jokey_phrases = ['humoristisk', 'joke', 'vits', 'for sjov', 'ironi', 'ironisk', 'sarkasme', 'sarkastisk', 'useriøs']\n",
    "    pattern = '|'.join(jokey_phrases)\n",
    "\n",
    "    df_exploded = df.explode('acceptable_solutions')\n",
    "    \n",
    "    jokey_rows_raw_text = df_exploded[\n",
    "        df_exploded['acceptable_solutions']\n",
    "        .str.contains(pattern, case=False, na=False)\n",
    "    ]\n",
    "\n",
    "    # save to csv for manual inspection\n",
    "    #jokey_rows_raw_text['acceptable_solutions'].to_csv('raw_text_jokes.csv')    \n",
    "\n",
    "    # after manual inspection, we've now identified the rows which contains joke answers (so actual joke-solutions, not just solutions mentioning a humoristic approach)\n",
    "    indices_to_clean = [107, 544, 685, 698, 1259, 1366, 1592, 1785, 1856, 1856, 2193, 2608, 2654, 2731, 2970, 3013, 73, 499, 1447, 1502, 1744, 1909, 2226, 2234, 2399]\n",
    "\n",
    "    # find the solutions to move in the dataframe containing all rows containing 'jokey' language\n",
    "    solutions_to_remove = jokey_rows_raw_text['acceptable_solutions'].loc[jokey_rows_raw_text.index.isin(indices_to_clean)]\n",
    "\n",
    "    # these position shares index labels with solutions that should be removed; these ones are NOT jokes however.\n",
    "    remove_positions = [8, 15, 16, 21, 25]\n",
    "\n",
    "    # need to do some manual cleanign with these\n",
    "    \n",
    "    # we can't remove by index, as there are several solutions at each row/index; instead, remove by text matching:\n",
    "    rows_to_remove = solutions_to_remove.iloc[remove_positions]\n",
    "    #print(rows_to_remove)  # just to see them\n",
    "\n",
    "    mask = np.ones(len(solutions_to_remove), dtype=bool) # start with all True\n",
    "    mask[remove_positions] = False # set positions to remove to False\n",
    "\n",
    "    solutions_to_remove_final = solutions_to_remove[mask] # <--- we need to remove these rows from the 'accepted_solutions' column\n",
    "\n",
    "    solutions_all = []\n",
    "    for i, row in df.iterrows():\n",
    "        solutions = row['acceptable_solutions']\n",
    "        \n",
    "        # make sure it's removing the correct rows\n",
    "        to_remove = [s for s in solutions if s in solutions_to_remove_final.tolist()]\n",
    "        if to_remove:\n",
    "            print(f\"Removing {to_remove} from row index {row.name}\")\n",
    "        \n",
    "        solutions_cleaned = [s for s in solutions if s not in solutions_to_remove_final.tolist()]\n",
    "        solutions_all.append(solutions_cleaned)\n",
    "    \n",
    "    return solutions_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7120036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_solutions(lst):\n",
    "    # Compile regexes once\n",
    "    deltagere_pattern = re.compile(r'deltager(?:e|ne)?(?:/\\w+)?\\s*:.*$', flags=re.IGNORECASE)\n",
    "    meta_labels = ['Orden', 'Betingelse', 'Rækkefølge', 'Aktør', 'Kræver', 'Ressourcer']\n",
    "    meta_pattern = re.compile(r'(' + '|'.join(meta_labels) + r')\\s*:.*$', flags=re.IGNORECASE)\n",
    "\n",
    "    cleaned = []\n",
    "    for s in lst:\n",
    "        s = s.strip()\n",
    "        # 0. Remove text in parentheses first\n",
    "        s = re.sub(r'\\s*\\([^)]*\\)', '', s).strip()\n",
    "        # 1. Remove deltager meta-comments\n",
    "        s = deltagere_pattern.sub('', s).strip()\n",
    "        # 2. Remove other meta-comments\n",
    "        s = meta_pattern.sub('', s).strip()\n",
    "        # 3. Replace trailing weird punctuation with a period, but keep ., ?, !\n",
    "        if s and s[-1] not in {'.', '?', '!'}:\n",
    "            s = re.sub(r'[\\W_]+$', '.', s)\n",
    "        cleaned.append(s)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af573a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove jokes:\n",
    "df['acceptable_solutions_cleaned'] = remove_jokes(df)\n",
    "\n",
    "# remove meta-comments:\n",
    "df['acceptable_solutions_cleaned'] = df['acceptable_solutions_cleaned'].apply(clean_solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6361e2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv\n",
    "df_cleaned = df.drop(['acceptable_solutions'], axis=1)\n",
    "\n",
    "df_cleaned.to_csv('../data/monopolet_cleaned.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
